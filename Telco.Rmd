---
title: "Telco"
author: "Anuar Baisynov, Martin Bech, Bawer Betasi, Thomas Matzen, Marius McIntosh"
date: "2022-10-30"
output:
  html_document:
    toc: yes
    theme: spacelab
    highlight: tango
    toc_depth: 2
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction

> Let's load the dataset first...

```{r}
telco <- read.csv("Telco-Customer-Churn.csv")
```

## Dataset Overview

> This dataset revolves itself around the **customer churn**. Inferably, the goal is thus to *use our progress in this course to predict the behavior of customers and thereby retain customers*, and perhaps provide preliminary findings for customer retention programs. As given away by the title, the data regards *"Telco"*, a hypothetical telecommunications company. Each row of the dataset is represented by a *customer*, and each column describes a *characteristic* of that customer and finally whether they have churned - or not. The dimensions of our dataset are: **`r dim(telco)`**, with **`r nrow(telco)`** rows and **`r ncol(telco)`** columns. Some descriptive statistics follow. 

```{r}
# Loading some data visualization packages...
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(gmodels))
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(C50))
suppressPackageStartupMessages(library(class))
suppressPackageStartupMessages(library(kernlab))
```

```{r}
# Rather than describing each column, have a look at the first few columns to 
# understand the structure of the dataset. 
head(telco)

# Of course, we could run an str() here, but we haven't cleaned the dataset yet. This might lead to some 
# confusion, but just beware that the "chr" variables will be turned into factors later on. Similarly, 
# summary() is mostly pointless due to the "chr" columns. 
str(telco)

# Let's look at the proportions of churn in our total set.
ggplot(data = telco, aes(x = Churn, fill = Churn)) + 
  geom_bar() + 
  theme_linedraw() + 
  theme(legend.position = "none") +
  coord_flip()

# We already see that the "yes" option occurs rather frequently,
# at more or less 1750 instances, whereas no occurs some 5100 times. However, we don't need to 
# guesstimate here! Let's check the rows of yes and no for more specific data instead.
nrow(filter(telco, Churn == "Yes"))

nrow(filter(telco, Churn == "No"))

#Proportion of churn
nrow(filter(telco, Churn == "Yes"))/nrow(telco)

# To be precise, we have 1869 customers churned out and 5174 retained. 

# Next, we can already, as a de facto habit, look at whether the response variable churn differs per
# gender. 
ggplot(data = telco, aes(x = Churn, fill = Churn)) + 
  geom_bar() + 
  theme_linedraw() + 
  facet_wrap(~gender)
# Without doing any other analysis, it appears to be the case that gender 
# does not significantly affect churn. The two charts are near identical both in proportion and 
# in size, indicating that there might be a near 50-50 split of gender across the churn count.
```

For the next descriptive section, let's have a look at churn per some variables that - intuitively - could impact customer churn in a telecom firm.

```{r}
# Let's start off with the DeviceProtection and how that impacts Churn. 
# We can also look at the proportions of Gender here.
ggplot(data = telco, aes(x = Churn, fill = gender)) + 
  geom_bar() + 
  theme_linedraw() + 
  facet_wrap(~DeviceProtection)
# Interesting finding here: for the "No" option in DeviceProtection, the churn is relatively high 
# compared to the other values in this category. Again, the male-female split appears to be almost 
# exactly 50% in every kind of DeviceProtection.

# Next, how does the tenure affect churn? Perhaps customers who have stuck around for a while will 
# continue to stick around and thus need less discounts, etc.?
ggplot(telco, aes(Churn, tenure, fill = Churn)) + 
  geom_boxplot(alpha = 0.8) +
  theme_linedraw() + 
  theme(legend.position = "none")

# Interesting! The tenure appears to be higher for those who don't churn than those who will. 
# We'll later explore whether this effect is significant. Perhaps, loyalty up to the present 
# day is an indicator of future loyalty, after all.


# Up next, let's look at Churn by the Contract type. Perhaps a flexible month-to-month contract 
# will result in more inclination to churn...
ggplot(telco, aes(Churn, fill = Churn)) + 
  geom_bar() + 
  theme_linedraw() + 
  theme(legend.position = "none") +
  facet_wrap(~Contract)

# Our suspicion appears to be confirmed! The month-to-month contract has an extremely high churn rate
# relative to the other contract types... we'll later see whether this is significant through our
# regression model.

# And what about Churn per Payment Method used? Is flexibility here also a cause of more churn? 
ggplot(telco, aes(Churn, fill = Churn)) + 
  geom_bar() + 
  theme_linedraw() + 
  theme(legend.position = "none") +
  facet_wrap(~PaymentMethod)

# By simply looking at this, our eyes are set on the electronic check method. Although it has a 
# similar "no" count as the other payment systems, the "yes" count is much, much higher! This is
# something we'd have to consider in our regression.

# What about Paperless Billing? Would the lack of a physical paper (that presumably needs to be signed)
# cause more churn? 
ggplot(telco, aes(Churn, fill = Churn)) + 
  geom_bar() + 
  theme_linedraw() + 
  theme(legend.position = "none") +
  facet_wrap(~PaperlessBilling)

# Again, something interesting. We see that "yes" (so paperless) results in more than double in churn.
# Whether the effect is significant is unknown, though - again, something to consider later on.

# Finally, what about online security? Are people less inclined to cancel their plan if they are 
# secured from malicious intents by the telecom's security system? 

ggplot(telco, aes(x = Churn, fill = Churn)) + 
  geom_bar() + 
  theme_linedraw() + 
  theme(legend.position = "none") +
  facet_wrap(~OnlineSecurity)

# The differences are night and day here: it's clear that when people do not have security in their
# plan, their churn rate is much, much higher. Again, significance must be given a final validation
# in the regression model.
```

As may be noticeable, we have thus far merely considered the effect of a given predictor on the response variable, Churn. That said, we can - of course - also look at the interaction between different predictors through visualization. For now, we've only done this once to save time and space (see below).

```{r}
# Let's check the interaction between Online Security and the Contract Type! Perhaps people with a
# flexible contract also opt out of fancy features such as security? This could help us know what to
# cater to with our offering when providing a month-to-month contract...

ggplot(telco, aes(x = OnlineSecurity, fill = OnlineSecurity)) + 
  geom_bar() + 
  facet_wrap(~Contract) + 
  theme_linedraw() + 
  theme(axis.text.x = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank())

# Again, very interesting! This chart shows us a lot of things. First, it shows us that most people
# have a month-to-month contract. Beyond that, however, it tells us that most people in a monthly
# contract opt out of security! For the one-year contract, the choice for online security is 
# almost split equally (omitting the "no internet service" category), whereas most people opt 
# in for online security given a two-year contract.
```

Of course, we can do **a lot more** with data visualization. For now, however, we'll keep it as is. A brief conclusion will follow before we move on to the next section.

### Conclusion

Overall, we've seen a lot of interesting findings that indicates the dataset's and analytical opportunities to drive down the customer churn rate. Exposing these correlations by purely considering business intuition also indicates the importance of *not merely running the code, but also using business judgment to apply the analytical know-how*. 

> We've seen that **gender** appears to be (somewhat) **indifferent** to the churn rate, whereas the **contract type, device protection, online security, and payment method** are variables to look out for. Additionally, we've realized that **interaction effects must be considered**, too, as a **month-to-month contract is almost always paired with no online security**. *Regardless, it is almost certain that we've missed numerous important effects, and that's why we'll run numerous types of ML algorithms and regression models.*

## Business Questions
> In this project, we are trying to answer **one overarching question**:

> *Can we, at least with a 90% accuracy, predict whether a certain customer will churn based on their demographic characteristics and product preferences?* To this end, we plan to create machine learning algorithms that will determine whether a given customer will eventually stop buying our services or not. Applying our models to multiple test cases will help us derive an accuracy score.

<<<<<<< HEAD
> Overall, our goal is to improve retention among both current and future customers. We can identify segments that have an unusually high churn rates and try to develop targeted retention strategies for them. 
=======
> Overall, our goal is two-fold: identify current customer segments that have an unusually high churn rate and try to develop targeted retention strategies for them.
>>>>>>> 91483c6fe216f4245fbaa593ef6be04881c919fb

## Preliminary Cleaning Effort
> In the upcoming section, the data is to be cleaned in order to prepare for data analysis, First, we start by deleting the "customerID" column as this column is irrelevant for our purpose (we're not trying to identify specific customers in our dataset). Following this, we factorize the columns with categorical data.

> After this, we go on to deal with the "TotalCharges" column. This column has some NA values, which we choose to replace by the median value of the column. We use the median value as this is outlier resistent and won't be influenced by the high/low values in the dataset. Lastly, we also update the Y-value to a numerical basis (Answer "No" will be a 0) to allow for better data analysis.

### Loading and Cleaning Data
```{r}
telco$customerID <- NULL

# Factorizing binary variables
telco$Churn <- as.factor(telco$Churn)
telco$PaperlessBilling <- as.factor(telco$PaperlessBilling)
telco$PhoneService <- as.factor(telco$PhoneService)
telco$Dependents <- as.factor(telco$Dependents)
telco$gender <- as.factor(telco$gender)
telco$SeniorCitizen <- as.factor(telco$SeniorCitizen)
telco$Partner <- as.factor(telco$Partner)

# Factorizing non-binary categorical variables
telco$PaymentMethod <- as.factor(telco$PaymentMethod)
telco$Contract <- as.factor(telco$Contract)
telco$InternetService <- as.factor(telco$InternetService)
telco$OnlineSecurity <- as.factor(telco$OnlineSecurity)
telco$OnlineBackup <- as.factor(telco$OnlineBackup)
telco$DeviceProtection <- as.factor(telco$DeviceProtection)
telco$TechSupport <- as.factor(telco$TechSupport)
telco$StreamingTV <- as.factor(telco$StreamingTV)
telco$StreamingMovies <- as.factor(telco$StreamingMovies)
telco$MultipleLines <- as.factor(telco$MultipleLines)

# Handling NA's
telco$TotalCharges[is.na(telco$TotalCharges)]<-median(telco$TotalCharges, na.rm=TRUE)

# Updating Y values
telco$Churn <- ifelse(telco$Churn == "No", 0, 1)

summary(telco)
str(telco)
```

### Normalization

```{r}
set.seed(12345)
telco_modelm <- as.data.frame(model.matrix(~., -1, data = telco))
telco_modelm$`(Intercept)` <- NULL

normalize <- function(x) {
  return((x-min(x))/(max(x)-min(x)))
}

telco_normal <- as.data.frame(lapply(telco_modelm, normalize))

telco_normal$Churn <- as.factor(telco_normal$Churn)

# Creating a label for our test set
telco_labels <- telco_normal$Churn
```


# Answering Business Question

For this section, we will check if we can predict with 90% accuracy whether someone will churn out of our telco offering. To do so, we will first build an ANN, kNN, LR, SVM, and DT prediction models, and then use those outputs to create an ensemble model. 

> The question is to be answered later in the semester. For the second intermediate deliverable, we are only building a stacked model based on the entire dataset without breaking it down into clusters.

# First-Level Models
## Logistic Regression
### Simple LR
```{r}
set.seed(300)
library(caret)

# Customize the tuning process using trainControl() to alter resampling strategy
ctrl <- trainControl(method = "cv", number = 4,
                     selectionFunction = "oneSE")

# Build LR model with the set resampling strategy and grid parameters
lr1 <- train(Churn ~ ., data = telco_normal, method = "glm", metric = "Kappa", trControl = ctrl)

# Show summary of the model
summary(lr1)

# Predict the test set
lr1pred <- predict(lr1, telco_normal[-31])

lm1_cm <- confusionMatrix(data = as.factor(lr1pred), reference = as.factor(telco_labels), positive = "1")

# Show the confusion matrix
lm1_cm

# Get accuracy and kappa values
lm1_acc <- as.numeric(lm1_cm$overall['Accuracy'])
lm1_kappa <- as.numeric(lm1_cm$overall['Kappa'])
lm1_sens <- as.numeric(lm1_cm$byClass['Sensitivity'])
```
<br>
> What immediately stands out in this model is the high number of **false negatives** where our model predicts that a customer would be retained (churn = 0), when it isn't the case in reality (i.e., they churned; churn = 1). Since this is an initial and relatively simple model, that is okay for now, as we will continue to work with this dataset to improve the prediction accuracy and bring down the false negatives simultaneously. This is the end of our code for the first intermediate submission.

### Improved LR
```{r}
set.seed(300)

# Build LR model with the set resampling strategy and grid parameters
lr2 <- train(Churn ~ SeniorCitizen1 + tenure + MultipleLinesYes + InternetServiceFiber.optic + InternetServiceNo + ContractOne.year + ContractTwo.year + PaperlessBillingYes + PaymentMethodElectronic.check + TotalCharges, data = telco_normal, method = "glm", metric = "Kappa", trControl = ctrl)

# Show summary of the model
summary(lr2)

# Predict the test set
lr2pred <- predict(lr2, telco_normal[-31])

lm2_cm <- confusionMatrix(data = as.factor(lr2pred), reference = as.factor(telco_labels), positive = "1")

# Show the confusion matrix
lm2_cm

# Get accuracy and kappa values
lm2_acc <- as.numeric(lm2_cm$overall['Accuracy'])
lm2_kappa <- as.numeric(lm2_cm$overall['Kappa'])
lm2_sens <- as.numeric(lm2_cm$byClass['Sensitivity'])
```

## ANN
```{r, cache = TRUE}
set.seed(300)

# Set up a grid to test different hidden layers
grid <- expand.grid(size = c(1, 3), decay = c(0, 0.05))

# Build ANN model with the set resampling strategy and grid parameters
ann1 <- caret::train(Churn ~ ., data = telco_normal, method = "nnet", metric = "Kappa", trControl = ctrl, tuneGrid = grid)

# Show summary of the model
summary(ann1)

# Predict the test set
ann1pred <- predict(ann1, telco_normal[-31])

ann1_cm <- confusionMatrix(data = as.factor(ann1pred), reference = as.factor(telco_labels), positive = "1")

# Show the confusion matrix
ann1_cm

# Get accuracy and kappa values
ann1_acc <- as.numeric(ann1_cm$overall['Accuracy'])
ann1_kappa <- as.numeric(ann1_cm$overall['Kappa'])
ann1_sens <- as.numeric(ann1_cm$byClass['Sensitivity'])
```
<br>
> First ANN gave us an accuracy score of``r ann1_acc` and a Kappa value of `r ann1_kappa`.

## kNN
```{r, cache = TRUE}
set.seed(300)

# Use expand.grid() to create grid of tuning parameters
grid <- expand.grid(k = seq(5, 100, 5))

# Build kNN models with the set resampling strategy and grid parameters
knn1 <- train(Churn ~ ., data = telco_normal, method = "knn",
           metric = "Kappa",
           trControl = ctrl,
           tuneGrid = grid)

# Predict the test set
knn1pred <- predict(knn1, telco_normal[-31])

# Create a confusion matrix
knn1_cm <- confusionMatrix(data = as.factor(knn1pred), reference = as.factor(telco_labels), positive = "1")

# Show the confusion matrix
knn1_cm

# Get accuracy and kappa values
knn1_acc <- as.numeric(knn1_cm$overall['Accuracy'])
knn1_kappa <- as.numeric(knn1_cm$overall['Kappa'])
knn1_sens <- as.numeric(knn1_cm$byClass['Sensitivity'])
```
<br>
> The kNN model achieved a higher accuracy (`r knn1_acc`) and a higher Kappa value (`r knn1_kappa`).

## Decision Tree
### Simple DT
```{r, cache = TRUE}
set.seed(300)

## Create a simple tuned model with automated parameter tuning of C5.0 decision tree 
dt1 <- train(Churn ~ ., data = telco_normal, method = "C5.0")

# Apply the best candidate model to make predictions
dt1_pred <- predict(dt1, telco_normal[-31])

# Create a confusion matrix
dt1_cm <- confusionMatrix(data = as.factor(dt1_pred), reference = as.factor(telco_labels), positive = "1")

# Show the confusion matrix
dt1_cm

# Get accuracy and kappa values
dt1_acc <- as.numeric(dt1_cm$overall['Accuracy'])
dt1_kappa <- as.numeric(dt1_cm$overall['Kappa'])
dt1_sens <- as.numeric(dt1_cm$byClass['Sensitivity'])
```
<br>
  > A model based on the Caret package saw a slightly higher accuracy (`r dt1_acc`)  but a lower Kappa value (`r dt1_kappa`). We will now try to tune the hyperparameters of the model.

```{r, cache = TRUE}
set.seed(300)

# Use expand.grid() to create grid of tuning parameters
grid <- expand.grid(.model = "tree",
                    .trials = c(1, 5, 10, 15, 20, 25, 30),
                    .winnow = "FALSE")

# Customize train() with the control list and grid of parameters 
dt2 <- train(Churn ~ ., data = telco_normal, method = "C5.0",
           metric = "Kappa",
           trControl = ctrl,
           tuneGrid = grid)

# Apply the best candidate model to make predictions
dt2_pred <- predict(dt2, telco_normal[-31])

# Create a confusion matrix
dt2_cm <- confusionMatrix(data = as.factor(dt2_pred), reference = as.factor(telco_labels), positive = "1")

dt2_cm

# Get accuracy and kappa values
dt2_acc <- as.numeric(dt2_cm$overall['Accuracy'])
dt2_kappa <- as.numeric(dt2_cm$overall['Kappa'])
dt2_sens <- as.numeric(dt2_cm$byClass['Sensitivity'])
```
<br>
> The improved model model based on the Caret package saw an accuracy of `r dt2_acc` and a Kappa value of `r dt2_kappa`.

## Support Vector Machine (SVM)
### SVM Linear
```{r, cache = TRUE}
set.seed(300)

# Customize train() with the control list and grid of parameters 
svm1 <- train(Churn ~ ., data = telco_normal, method = "svmLinear",
           metric = "Kappa",
           trControl = ctrl)

# Apply the best candidate model to make predictions
svm1_pred <- predict(svm1, telco_normal[-31])

# Create a confusion matrix
svm1_cm <- confusionMatrix(data = as.factor(svm1_pred), reference = as.factor(telco_labels), positive = "1")

# Show the confusion matrix
svm1_cm

# Get accuracy and kappa values
svm1_acc <- as.numeric(svm1_cm$overall['Accuracy'])
svm1_kappa <- as.numeric(svm1_cm$overall['Kappa'])
svm1_sens <- as.numeric(svm1_cm$byClass['Sensitivity'])
```
<br>
> The SVM model with a linear kernel achieved an accuracy of `r svm1_acc` and a Kappa value of `r svm1_kappa`.

### SVM Radial
```{r, cache = TRUE}
set.seed(300)

# Customize train() with the control list and grid of parameters 
svm2 <- train(Churn ~ ., data = telco_normal, method = "svmRadial",
           metric = "Kappa",
           trControl = ctrl)

# Apply the best candidate model to make predictions
svm2_pred <- predict(svm2, telco_normal[-31])

# Create a confusion matrix
svm2_cm <- confusionMatrix(data = as.factor(svm2_pred), reference = as.factor(telco_labels), positive = "1")

# Show the confusion matrix
svm2_cm

# Get accuracy and kappa values
svm2_acc <- as.numeric(svm2_cm$overall['Accuracy'])
svm2_kappa <- as.numeric(svm2_cm$overall['Kappa'])
svm2_sens <- as.numeric(svm2_cm$byClass['Sensitivity'])
```
<br>
> The SVM model with a radial kernel achieved an accuracy of `r svm2_acc` and a Kappa value of `r svm2_kappa`.

### SVM Poly
```{r, cache = TRUE}
set.seed(300)

# Customize train() with the control list and grid of parameters 
svm3 <- train(Churn ~ ., data = telco_normal, method = "svmPoly",
           metric = "Kappa",
           trControl = ctrl)

# Apply the best candidate model to make predictions
svm3_pred <- predict(svm3, telco_normal[-31])

# Create a confusion matrix
svm3_cm <- confusionMatrix(data = as.factor(svm3_pred), reference = as.factor(telco_labels), positive = "1")

# Show the confusion matrix
svm3_cm

# Get accuracy and kappa values
svm3_acc <- as.numeric(svm3_cm$overall['Accuracy'])
svm3_kappa <- as.numeric(svm3_cm$overall['Kappa'])
svm3_sens <- as.numeric(svm3_cm$byClass['Sensitivity'])
```
<br>
> The SVM model with a poly kernel achieved an accuracy of `r svm3_acc` and a Kappa value of `r svm3_kappa`.

## First-Layer Results

```{r}
# Combine all accuracy, kappa, and sensitivity values
accuracy <- c(lm1_acc, lm2_acc, ann1_acc, knn1_acc, dt1_acc, dt2_acc, svm1_acc, svm2_acc, svm3_acc)
kappa <- c(lm1_kappa, lm2_kappa, ann1_kappa, knn1_kappa, dt1_kappa, dt2_kappa, svm1_kappa, svm2_kappa, svm3_kappa)
sens <- c(lm1_sens, lm2_sens, ann1_sens, knn1_sens, dt1_sens, dt2_sens, svm1_sens, svm2_sens, svm3_sens)

# Create a dataframe with all values
results <- data.frame(accuracy, kappa, sens)
rownames(results) <- c("LR1", "LR2", "ANN1", "kNN1", "DT1", "DT2", "SVM1", "SVM2", "SVM3")
colnames(results) <- c("Accuracy", "Kappa", "Sensitivity")

# Show the created dataframe
results
```

# Second-Level Model

```{r}
# Combine everything into one big dataframe for our stacked model.
combineddf <- data.frame(lr1pred, ann1pred, knn1pred, dt2_pred, svm2_pred, telco_labels)

# Change colnames to something more intuitive
colnames(combineddf) <- c("LR", "ANN", "kNN", "DT", "SVM", "Actual")

# Show summary statistics for the dataframe
summary(combineddf)
```

## Simple Stacked Model
```{r, cache = TRUE}
set.seed(300)

# Use expand.grid() to create grid of tuning parameters
grid <- expand.grid(.model = "tree",
                    .trials = c(1, 5, 10, 15, 20, 25, 30),
                    .winnow = "FALSE")

# Customize train() with the control list and grid of parameters 
dt_comb <- train(Actual ~ ., data = combineddf, method = "C5.0",
           metric = "Kappa",
           trControl = ctrl,
           tuneGrid = grid)

# Apply the best candidate model to make predictions
dt_comb_pred <- predict(dt_comb, combineddf[-6])

# Create a confusion matrix
dt_comb_cm <- confusionMatrix(data = as.factor(dt_comb_pred), reference = as.factor(combineddf$Actual), positive = "1")

# Show the confusion matrix
dt_comb_cm

# Get accuracy and kappa values
dt_comb_acc <- as.numeric(dt_comb_cm$overall['Accuracy'])
dt_comb_kappa <- as.numeric(dt_comb_cm$overall['Kappa'])
dt_comb_sens <- as.numeric(dt_comb_cm$byClass['Sensitivity'])
```
<br>
> The combined model achieved an accuracy of `r dt_comb_acc`, a Kappa value of `r dt_comb_kappa`, and a sensitivity score of `r dt_comb_sens`. 

```{r}
# Combine all accuracy, kappa, and sensitivity values
accuracy <- c(lm1_acc, ann1_acc, knn1_acc, dt2_acc, svm2_acc, dt_comb_acc)
kappa <- c(lm1_kappa, ann1_kappa, knn1_kappa, dt2_kappa, svm2_kappa, dt_comb_kappa)
sens <- c(lm1_sens, ann1_sens, knn1_sens, dt2_sens, svm2_sens, dt_comb_sens)

# Create a dataframe with all values
results <- data.frame(accuracy, kappa, sens)
rownames(results) <- c("LR1", "ANN1", "kNN1", "DT2", "SVM2", "Combined")
colnames(results) <- c("Accuracy", "Kappa", "Sensitivity")

# Show the created dataframe
results
```
<br>
> Thus, the combined model has achieved the highest accuracy score and Kappa value, but its sensitivity is lower than that of ANN and kNN. In this project, we are specifically interested in minimizing the number of false negatives - unnoticed instances of churn. We will try to reduce that number (and thus increase the combined model's sensitivity score) using an **error cost matrix**.

## Error Cost Matrix - NEED TO UPDATE
```{r}
# Create a cost matrix
error_cost <- matrix(c(0, 1, 3, 0), nrow = 2)

# Apply the cost matrix to the tree
comb_dt2 <- C5.0(sm_telco_train[-6], as.factor(sm_telco_train$Actual), costs = error_cost)
comb_dtpred2 <- predict(comb_dt2, sm_telco_test)

# Build a confusion matrix
dt_comb2_cm <- confusionMatrix(data = as.factor(comb_dtpred2), reference = as.factor(sm_telco_test$Actual), positive = "1")

dt_comb2_cm

# Get accuracy and kappa values
dt_comb2_acc <- as.numeric(dt_comb2_cm$overall['Accuracy'])
dt_comb2_kappa <- as.numeric(dt_comb2_cm$overall['Kappa'])
dt_comb2_sens <- as.numeric(dt_comb2_cm$byClass['Sensitivity'])
```
<br>
> By applying a cost matrix, we can increase our senstivity score to `r dt_comb2_sens` but the accuracy rate falls to `r dt_comb2_acc`. That is primarily because we are increasing the number of false positives. The goal of our project is to identify individuals with a high risk of churn and target them with retention strategies. In our next submission for this project, we will look into the costs associated with losing customers as well as running such retention strategies. With that information, we will be able to estimate how much money the company will be able to save by targeting only customers who are at risk of churn according to the model.

```{r, cache = TRUE}
set.seed(300)

# Create a cost matrix
error_cost <- matrix(c(0, 1, 3, 0), nrow = 2)

# Use expand.grid() to create grid of tuning parameters
grid <- expand.grid(.model = "tree",
                    .trials = c(1, 5, 10, 15, 20, 25, 30),
                    .winnow = "FALSE",
                    cost <- error_cost)

# Customize train() with the control list and grid of parameters 
dt_comb <- train(Actual ~ ., data = combineddf, method = "C5.0Cost",
           metric = "Kappa",
           trControl = ctrl,
           tuneGrid = grid)

# Apply the best candidate model to make predictions
dt_comb_pred <- predict(dt_comb, combineddf[-6])

# Create a confusion matrix
dt_comb_cm <- confusionMatrix(data = as.factor(dt_comb_pred), reference = as.factor(combineddf$Actual), positive = "1")

# Show the confusion matrix
dt_comb_cm

# Get accuracy and kappa values
dt_comb_acc <- as.numeric(dt_comb_cm$overall['Accuracy'])
dt_comb_kappa <- as.numeric(dt_comb_cm$overall['Kappa'])
dt_comb_sens <- as.numeric(dt_comb_cm$byClass['Sensitivity'])
```

```{r}
# Extract numbers from the table
TN = as.numeric(dt_comb2_cm$table)[1]
FP = as.numeric(dt_comb2_cm$table)[2]
FN = as.numeric(dt_comb2_cm$table)[3]
TP = as.numeric(dt_comb2_cm$table)[4]

customers_at_risk = TP + FN
customers_targeted = TP + FP
```

