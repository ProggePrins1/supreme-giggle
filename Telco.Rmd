---
title: "Telco"
author: "Anuar Baisynov, Martin Bech, Bawer Betasi, Thomas Matzen, Marius McIntosh"
date: "2022-10-30"
output:
  html_document:
    toc: yes
    theme: spacelab
    highlight: tango
    toc_depth: 2
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction

> Let's load the dataset first...

```{r}
telco <- read.csv("Telco-Customer-Churn.csv")
```

## Dataset Overview

> This dataset revolves itself around the **customer churn**. Inferably, the goal is thus to *use our progress in this course to predict the behavior of customers and thereby retain customers*, and perhaps provide preliminary findings for customer retention programs. As given away by the title, the data regards *"Telco"*, a hypothetical telecommunications company. Each row of the dataset is represented by a *customer*, and each column describes a *characteristic* of that customer and finally whether they have churned - or not. The dimensions of our dataset are: **`r dim(telco)`**, with **`r nrow(telco)`** rows and **`r ncol(telco)`** columns. Some descriptive statistics follow. 

```{r}
# Loading some data visualization packages...
library(ggplot2)
library(dplyr)
```

```{r}
# Rather than describing each column, have a look at the first few columns to 
# understand the structure of the dataset. 
head(telco)

# Of course, we could run an str() here, but we haven't cleaned the dataset yet. This might lead to some 
# confusion, but just beware that the "chr" variables will be turned into factors later on. Similarly, 
# summary() is mostly pointless due to the "chr" columns. 
str(telco)

# Let's look at the proportions of churn in our total set.
ggplot(data = telco, aes(x = Churn, fill = Churn)) + 
  geom_bar() + 
  theme_linedraw() + 
  theme(legend.position = "none") +
  coord_flip()

# We already see that the "yes" option occurs rather frequently,
# at more or less 1750 instances, whereas no occurs some 5100 times. However, we don't need to 
# guesstimate here! Let's check the rows of yes and no for more specific data instead.
nrow(filter(telco, Churn == "Yes"))

nrow(filter(telco, Churn == "No"))

# To be precise, we have 1869 customers churned out and 5174 retained. 

# Next, we can already, as a de facto habit, look at whether the response variable churn differs per
# gender. 
ggplot(data = telco, aes(x = Churn, fill = Churn)) + 
  geom_bar() + 
  theme_linedraw() + 
  facet_wrap(~gender)
# Without doing any other analysis, it appears to be the case that gender 
# does not significantly affect churn. The two charts are near identical both in proportion and 
# in size, indicating that there might be a near 50-50 split of gender across the churn count.
```

For the next descriptive section, let's have a look at churn per some variables that - intuitively - could impact customer churn in a telecom firm.

```{r}
# Let's start off with the DeviceProtection and how that impacts Churn. 
# We can also look at the proportions of Gender here.
ggplot(data = telco, aes(x = Churn, fill = gender)) + 
  geom_bar() + 
  theme_linedraw() + 
  facet_wrap(~DeviceProtection)
# Interesting finding here: for the "No" option in DeviceProtection, the churn is relatively high 
# compared to the other values in this category. Again, the male-female split appears to be almost 
# exactly 50% in every kind of DeviceProtection.

# Next, how does the tenure affect churn? Perhaps customers who have stuck around for a while will 
# continue to stick around and thus need less discounts, etc.?
ggplot(telco, aes(Churn, tenure, fill = Churn)) + 
  geom_boxplot(alpha = 0.8) +
  theme_linedraw() + 
  theme(legend.position = "none")

# Interesting! The tenure appears to be higher for those who don't churn than those who will. 
# We'll later explore whether this effect is significant. Perhaps, loyalty up to the present 
# day is an indicator of future loyalty, after all.


# Up next, let's look at Churn by the Contract type. Perhaps a flexible month-to-month contract 
# will result in more inclination to churn...
ggplot(telco, aes(Churn, fill = Churn)) + 
  geom_bar() + 
  theme_linedraw() + 
  theme(legend.position = "none") +
  facet_wrap(~Contract)

# Our suspicion appears to be confirmed! The month-to-month contract has an extremely high churn rate
# relative to the other contract types... we'll later see whether this is significant through our
# regression model.

# And what about Churn per Payment Method used? Is flexibility here also a cause of more churn? 
ggplot(telco, aes(Churn, fill = Churn)) + 
  geom_bar() + 
  theme_linedraw() + 
  theme(legend.position = "none") +
  facet_wrap(~PaymentMethod)

# By simply looking at this, our eyes are set on the electronic check method. Although it has a 
# similar "no" count as the other payment systems, the "yes" count is much, much higher! This is
# something we'd have to consider in our regression.

# What about Paperless Billing? Would the lack of a physical paper (that presumably needs to be signed)
# cause more churn? 
ggplot(telco, aes(Churn, fill = Churn)) + 
  geom_bar() + 
  theme_linedraw() + 
  theme(legend.position = "none") +
  facet_wrap(~PaperlessBilling)

# Again, something interesting. We see that "yes" (so paperless) results in more than double in churn.
# Whether the effect is significant is unknown, though - again, something to consider later on.

# Finally, what about online security? Are people less inclined to cancel their plan if they are 
# secured from malicious intents by the telecom's security system? 

ggplot(telco, aes(x = Churn, fill = Churn)) + 
  geom_bar() + 
  theme_linedraw() + 
  theme(legend.position = "none") +
  facet_wrap(~OnlineSecurity)

# The differences are night and day here: it's clear that when people do not have security in their
# plan, their churn rate is much, much higher. Again, significance must be given a final validation
# in the regression model.
```

As may be noticeable, we have thus far merely considered the effect of a given predictor on the response variable, Churn. That said, we can - of course - also look at the interaction between different predictors through visualization. For now, we've only done this once to save time and space (see below).

```{r}
# Let's check the interaction between Online Security and the Contract Type! Perhaps people with a
# flexible contract also opt out of fancy features such as security? This could help us know what to
# cater to with our offering when providing a month-to-month contract...

ggplot(telco, aes(x = OnlineSecurity, fill = OnlineSecurity)) + 
  geom_bar() + 
  facet_wrap(~Contract) + 
  theme_linedraw() + 
  theme(axis.text.x = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank())

# Again, very interesting! This chart shows us a lot of things. First, it shows us that most people
# have a month-to-month contract. Beyond that, however, it tells us that most people in a monthly
# contract opt out of security! For the one-year contract, the choice for online security is 
# almost split equally (omitting the "no internet service" category), whereas most people opt 
# in for online security given a two-year contract.
```

Of course, we can do **a lot more** with data visualization. For now, however, we'll keep it as is. A brief conclusion will follow before we move on to the next section.

### Conclusion

Overall, we've seen a lot of interesting findings that indicates the dataset's and analytical opportunities to drive down the customer churn rate. Exposing these correlations by purely considering business intuition also indicates the importance of *not merely running the code, but also using business judgment to apply the analytical know-how*. 

> We've seen that **gender** appears to be (somewhat) **indifferent** to the churn rate, whereas the **contract type, device protection, online security, and payment method** are variables to look out for. Additionally, we've realized that **interaction effects must be considered**, too, as a **month-to-month contract is almost always paired with no online security**. *Regardless, it is almost certain that we've missed numerous important effects, and that's why we'll run numerous types of ML algorithms and regression models.*

## Business Question
> In this project, we are trying to answer **two overarching questions**:

> 1) *Are there customer groups with certain demographic characteristics or product preferences that tend to stop buying our services more often than others?* We will try to investigate this in two ways. First, we will try to explore differences in churn rates across various explanatory features in our dataset (Exploratory Data Analysis section). Next, we will try to aggregate the data by running the k-means clustering algorithm to identify customer segments with the highest churn rate (Clustering section).

> 2) *Can we, at least with a 90% accuracy, predict whether a certain customer will churn based on their demographic characteristics and product preferences?* To this end, we plan to create machine learning algorithms that will determine whether a given customer will eventually stop buying our services or not. Applying our models to multiple test cases will help us derive an accuracy score.

<<<<<<< HEAD
> Overall, our goal is to improve retention among both current and future customers. We can identify segments that have an unusually high churn rates and try to develop targeted retention strategies for them. 
=======
> Overall, our goal is two-fold: identify current customer segments that have an unusually high churn rate and try to develop targeted retention strategies for them.
>>>>>>> 91483c6fe216f4245fbaa593ef6be04881c919fb

## Preliminary Cleaning Effort
> In the upcoming section, the data is to be cleaned in order to prepare for data analysis, First, we start by deleting the "customerID" column as this column is irrelevant for our purpose (we're not trying to identify specific customers in our dataset). Following this, we factorize the columns with categorical data.

> After this, we go on to deal with the "TotalCharges" column. This column has some NA values, which we choose to replace by the median value of the column. We use the median value as this is outlier resistent and won't be influenced by the high/low values in the dataset. Lastly, we also update the Y-value to a numerical basis (Answer "No" will be a 0) to allow for better data analysis.

### Loading and Cleaning Data
```{r}
telco$customerID <- NULL

# Factorizing binary variables
telco$Churn <- as.factor(telco$Churn)
telco$PaperlessBilling <- as.factor(telco$PaperlessBilling)
telco$PhoneService <- as.factor(telco$PhoneService)
telco$Dependents <- as.factor(telco$Dependents)
telco$gender <- as.factor(telco$gender)
telco$SeniorCitizen <- as.factor(telco$SeniorCitizen)
telco$Partner <- as.factor(telco$Partner)

# Factorizing non-binary categorical variables
telco$PaymentMethod <- as.factor(telco$PaymentMethod)
telco$Contract <- as.factor(telco$Contract)
telco$InternetService <- as.factor(telco$InternetService)
telco$OnlineSecurity <- as.factor(telco$OnlineSecurity)
telco$OnlineBackup <- as.factor(telco$OnlineBackup)
telco$DeviceProtection <- as.factor(telco$DeviceProtection)
telco$TechSupport <- as.factor(telco$TechSupport)
telco$StreamingTV <- as.factor(telco$StreamingTV)
telco$StreamingMovies <- as.factor(telco$StreamingMovies)
telco$MultipleLines <- as.factor(telco$MultipleLines)

# Handling NA's
telco$TotalCharges[is.na(telco$TotalCharges)]<-median(telco$TotalCharges, na.rm=TRUE)

# Updating Y values
telco$Churn <- ifelse(telco$Churn == "No", 0, 1)

summary(telco)
str(telco)
```
## <a id="train_test"></a>Creating train and test sets


```{r}

## Loading the neccessary packages

set.seed(123)
library(gmodels)
library(caret)

telco_sample <- sample(c(TRUE, FALSE), nrow(telco), replace=TRUE, prob=c(0.75,0.25))

telco_train  <- telco[telco_sample, ]
telco_test   <- telco[!telco_sample, ]

# Creating a label for our test set
telco_test_labels <- telco_test$Churn


# Removing the response variable
telco_test$Churn <- NULL

predictionmodelt1 <- glm(Churn ~ ., data = telco_train, family = "binomial")
summary(predictionmodelt1)

# Let's now run a model with only the significant variables, with a p-value threshold of 0.05.

predictionmodelt2 <- glm(Churn ~ tenure + InternetService + Contract + PaperlessBilling + PaymentMethod + TotalCharges, data = telco_train, family = "binomial")

summary(predictionmodelt2)

# We can can now run our initial prediction based on this simple logistic regression. 
# We'll use a threshold of 50% here.

initialprediction1 <- ifelse(predict(predictionmodelt2, newdata = telco_test, type = "response") < 0.5, 0, 1)

CrossTable(telco_test_labels, initialprediction1, prop.chisq = FALSE)

confusionMatrix(data = as.factor(initialprediction1), reference = as.factor(telco_test_labels), positive = "1")

```

## Initial Interpretation

> What immediately stands out in this model is the high number of **false negatives (195)** where our model predicts that a customer would be retained (churn = 0), when it isn't the case in reality (i.e., they churned; churn = 1). Since this is an initial and relatively simple model, that is okay for now, as we will continue to work with this dataset to improve the prediction accuracy and bring down the false negatives simultaneously. That's all for now, but all is to be continued...